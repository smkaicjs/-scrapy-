# -*- coding: utf-8 -*-import scrapyfrom urllib import parseimport refrom amazon.items import AmItemclass OneTestSpider(scrapy.Spider):    name = 'one_test'    allowed_domains = ['amazon.cn']    key_world = input("商品关键词：")    start_urls = ['https://www.amazon.cn/s?k=' + key_world + '&i=amazon-global-store&srs=1403206071&__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&ref=nb_sb_noss_1']    custom_settings = { 'DEFAULT_REQUEST_HEADERS':{        'Accept': 'application / json, text / javascript, * / *;q = 0.01',        'Accept - Encoding':'gzip, deflate, br',        'Accept - Language':'zh - CN, zh;q = 0.9',        'Connection':'keep - alive',        'Cookie':'session - id = 460 - 3862659 - 7012005;s_pers = % 20s_fid % 3D4EA95891932F489A - 006C159B3599666E % 7C1743572157064 % 3B % 20s_dl % 3D1 % 7C1585807557081 % 3B % 20gpv_page % 3DCN % 253AAS % 253AGS - homepage % 7C1585807557087 % 3B % 20s_ev15 % 3D % 255B % 255B % 2527SECNAGSbaidubztitle % 2527 % 252C % 25271585805757096 % 2527 % 255D % 255D % 7C1743572157096 % 3B;ubid - acbcn = 462 - 2591745 - 2648219;s_sess = % 20c_m % 3DSECNAGSbaidubztitlesp0.baidu.comPaid % 2520Searchundefined % 3B % 20s_cc % 3Dtrue % 3B % 20s_ppvl % 3DCN % 25253AAS % 25253AGS - homepage % 252C20 % 252C20 % 252C620 % 252C1252 % 252C620 % 252C1778 % 252C1000 % 252C1.08 % 252CL % 3B % 20s_ppv % 3DCN % 25253AAS % 25253AGS - homepage % 252C40 % 252C19 % 252C1320 % 252C1252 % 252C620 % 252C1778 % 252C1000 % 252C1.08 % 252CL % 3B;i18n - prefs = CNY;x - wl - uid = 16Z8uLqomAScROcICrCdX7oHC / jMWR9N9hxGknIIkZ1wGBdeR6donu + F5flDxPnCTuyfMEWfjGDs =;session - token = Mag9qJNd8 + nU1TEYShDr8gQo + OxwpZrVJ3xOJKDfY + pwHQVzp9RN2H3evka1UMj2q / 9K3F2op0HJid8N7plSlUkDAziijCKky4NaCY49VUbUrgXtTY8AAHOGjhPyaxidE35lEwPor3K7Hw55f423Byga15IbUzNaMo2WMcZ8o30Wc4gNLFavDuD96wYOcOyo;session - id - time = 2082729601l;csm - hit = tb:CNMW15MQMK5QA231A9BG + s - 3QEX95XAXFV5J0YJQZ1J | 1585819201995 & t: 1585819201995 & adb:adblk_no',        'Host':'www.amazon.cn',        'Referer':'https: // www.amazon.cn / s?k = % E7 % A7 % 8B % E8 % A1 % A3 & i = amazon -global-store & srs = 1403206071 & __mk_zh_CN = % E4 % BA % 9A % E9 % A9 % AC % E9 % 80 % 8A % E7 % BD % 91 % E7 % AB % 99 & crid = 1A4QVI3QMIJQ4 & sprefix = qiu % 2Camazon -global-store % 2C195 & ref = nb_sb_ss_i_4_3',        'User - Agent':'Mozilla / 5.0(Windows NT 10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 80.0.3987.132Safari / 537.36'    }    }    def parse(self, response):        response.encode = 'utf-8'        name = response.xpath("//div[@class='s-result-list s-search-results sg-row']//div[@class='a-section a-spacing-medium']/div[@class='a-section a-spacing-none a-spacing-top-small']/h2/a/@href").extract()        num = 0        for na in name:            num += 1            na = parse.urljoin('https://www.amazon.cn/',na)            print('本页解析到',num,'个商品')            yield scrapy.Request(na,callback=self.deta_page)        next_page = response.xpath("//ul[@class='a-pagination']/li[@class='a-last']/a/@href").extract_first()        page_num = re.search('^/.*page=([0-9]+)',next_page)        page_num = page_num.group(1)        print('第',page_num,'页完成')        if next_page:            next_page = 'https://www.amazon.cn/'+next_page            yield scrapy.Request(next_page,callback=self.parse)    def deta_page(self,response):        item = AmItem()        title = response.xpath("//span[@id='productTitle']/text()").extract_first()        title = ''.join(title).replace(' ','').replace('\r','').replace('\n','')        price = response.xpath("//td[@class='a-span12']/span[@id='priceblock_ourprice']/text()").extract_first()        size = response.xpath("//div[@id='variation_size_name']//span/text()").extract_first()        style = response.xpath("//div[@id='variation_style_name']//span/text()").extract_first()        try:            item['title'] = title        except:            pass        try:            item['style'] = style        except:            pass        try:            item['size'] = size        except:            pass        try:            item['price'] = price        except:            pass        yield item